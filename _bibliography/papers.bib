@inproceedings{metzen2017universal,
  title={Universal Adversarial Perturbations Against Semantic Image Segmentation},
  author={Metzen, Jan Hendrik and Kumar, Mummadi Chaithanya and Brox, Thomas and Fischer, Volker},
  booktitle = {submitted},
  url = {https://arxiv.org/abs/1704.05712},
  year={2017}
}

@inproceedings{fischer2017adversarial,
  title={Adversarial Examples for Semantic Image Segmentation},
  author={Fischer, Volker and Kumar, Mummadi Chaithanya and Metzen, Jan Hendrik and Brox, Thomas},
  booktitle = {Proceedings of 5th International Conference on Learning Representations (ICLR), Workshop paper},
  year={2017}
  url = {https://arxiv.org/abs/1703.01101},
}

@inproceedings{metzen2017detecting,
  title={On Detecting Adversarial Perturbations},
  author={Metzen, Jan Hendrik and Genewein, Tim and Fischer, Volker and Bischoff, Bastian},
  booktitle = {Proceedings of 5th International Conference on Learning Representations (ICLR)},
  year={2017}
  url = {https://arxiv.org/abs/1702.04267}
}

@inproceedings{metzen_mrs_2016,
	address = {New York, NY, USA},
	title = {Minimum Regret Search for Single- and Multi-Task Optimization},
	booktitle = {Proceedings of 33rd International Conference on Machine Learning (ICML)},
	author = {Metzen, Jan Hendrik},
	year = {2016},
	keywords = {active-learning, bayesian-optimization, multi-task-learning, policy-search},
	pages = {10},
	abstract = {We propose minimum regret search (MRS), a novel acquisition function for Bayesian optimization. MRS bears similarities with information-theoretic approaches such as entropy search (ES). However, while ES aims in each query at maximizing the information gain with respect to the global maximum, MRS aims at minimizing the expected immediate regret of its ultimate recommendation for the optimum. While empirically ES and MRS perform similar in most of the cases, MRS produces fewer outliers with high regret than ES. We provide empirical results both for a synthetic single-task optimization problem as well as for a simulated multi-task robotic control problem.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Bayesian Optimization},
	url = {http://arxiv.org/abs/1602.01064},
}

@inproceedings{metzen_mrs_2016,
	address = {New York, NY, USA},
	title = {Minimum Regret Search for Single- and Multi-Task Optimization},
	booktitle = {Proceedings of 33rd International Conference on Machine Learning (ICML)},
	author = {Metzen, Jan Hendrik},
	year = {2016},
	keywords = {active-learning, bayesian-optimization, multi-task-learning, policy-search},
	pages = {10},
	abstract = {We propose minimum regret search (MRS), a novel acquisition function for Bayesian optimization. MRS bears similarities with information-theoretic approaches such as entropy search (ES). However, while ES aims in each query at maximizing the information gain with respect to the global maximum, MRS aims at minimizing the expected immediate regret of its ultimate recommendation for the optimum. While empirically ES and MRS perform similar in most of the cases, MRS produces fewer outliers with high regret than ES. We provide empirical results both for a synthetic single-task optimization problem as well as for a simulated multi-task robotic control problem.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Bayesian Optimization},
	url = {http://arxiv.org/abs/1602.01064},
}

@article{vanderpoorten_cognitive_2016,
	title = {Cognitive AutonomouS CAtheters operating in Dynamic Environments},
	journal = {Journal of Medical Robotics Research},
	author = {Vander Poorten, Emmanuel and et al.},
	year = {2016},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {}
}

@inproceedings{metzen_active_2015,
	address = {Montreal, Quebec, Canada},
	title = {Active {Contextual} {Entropy} {Search}},
	booktitle = {Proceedings of {NIPS} {Workshop} on {Bayesian} {Optimization}},
	author = {Metzen, Jan Hendrik},
	year = {2015},
	keywords = {active-learning, bayesian-optimization, multi-task-learning, policy-search},
	pages = {5},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Bayesian Optimization},
	url = {http://arxiv.org/abs/1511.04211},
}

@article{kassahun_surgical_2015,
	title = {Surgical {Robotics} {Beyond} {Enhanced} {Dexterity} {Instrumentation}},
	journal = {International Journal of Computer Assisted Radiology and Surgery},
	author = {Kassahun, Yohannes and Yu, Bingbin and Tibebu, Abraham Temesgen and Stoyanov, Danail and Giannarou, Stamatia and Metzen, Jan Hendrik and Vander Poorten, Emmanuel},
	year = {2015},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {}
}

@inproceedings{metzen_bayesian_2015,
	address = {Hamburg},
	title = {Bayesian {Optimization} for {Contextual} {Policy} {Search}},
	abstract = {Contextual policy search allows adapting robotic movement primitives to different situations. For instance, a locomotion primitive might be adapted to different terrain inclinations or desired walking speeds. Such an adaptation is often achievable by modifying a relatively small number of hyperparameters; however, learning when performed on an actual robotic system is typically restricted to a relatively small number of trials. In black-box optimization, Bayesian optimization is a popular global search approach for addressing such problems with low-dimensional search space but expensive cost function. We present an extension of Bayesian optimization to contextual policy search. Preliminary results suggest that Bayesian optimization outperforms local search approaches on low-dimensional contextual policy search problems.},
	booktitle = {Proceedings of the {Second} {Machine} {Learning} in {Planning} and {Control} of {Robot} {Motion} {Workshop} (MLPC-2015).},
	publisher = {IROS},
	author = {Metzen, Jan Hendrik and Fabisch, Alexander and Hansen, Jonas},
	year = {2015},
	keywords = {bayesian-optimization, multi-task-learning, policy-search},
	url = {http://www.cs.unm.edu/~afaust/MLPC15_proceedings/MLPC15_paper_Metzen.pdf},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Bayesian Optimization}
}

@incollection{kirchner_intuitive_2015,
	title = {Intuitive {Interaction} with {Robots} – {Technical} {Approaches} and {Challenges}},
	isbn = {978-3-658-09993-0 978-3-658-09994-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-658-09994-7_8},
	language = {en},
	urldate = {2015-09-22},
	booktitle = {Formal {Modeling} and {Verification} of {Cyber}-{Physical} {Systems}},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Kirchner, Elsa Andrea and Fernandez, Jose de Gea and Kampmann, Peter and Schr{\"o}er, Martin and Metzen, Jan Hendrik and Kirchner, Frank},
	editor = {Drechsler, Rolf and K{\"u}hne, Ulrich},
	year = {2015},
	pages = {224--248},
        bib2html_pubtype = {Book Chapter},
        bib2html_rescat = {}
}

@incollection{kirchner_intuitive_2015,
	title = {Intuitive {Interaction} with {Robots} – {Technical} {Approaches} and {Challenges}},
	isbn = {978-3-658-09993-0 978-3-658-09994-7},
	url = {http://link.springer.com/chapter/10.1007/978-3-658-09994-7_8},
	language = {en},
	urldate = {2015-09-22},
	booktitle = {Formal {Modeling} and {Verification} of {Cyber}-{Physical} {Systems}},
	publisher = {Springer Fachmedien Wiesbaden},
	author = {Kirchner, Elsa Andrea and Fernandez, Jose de Gea and Kampmann, Peter and Schr{\"o}er, Martin and Metzen, Jan Hendrik and Kirchner, Frank},
	editor = {Drechsler, Rolf and K{\"u}hne, Ulrich},
	year = {2015},
	pages = {224--248},
        bib2html_pubtype = {Book Chapter},
        bib2html_rescat = {}
}

@article{fabisch_accounting_2015,
	title = {Accounting for {Task}-{Difficulty} in {Active} {Multi}-{Task} {Robot} {Control} {Learning}},
	issn = {0933-1875, 1610-1987},
	url = {http://link.springer.com/article/10.1007/s13218-015-0363-2},
	doi = {10.1007/s13218-015-0363-2},
	abstract = {Contextual policy search is a reinforcement learning approach for multi-task learning in the context of robot control learning. It can be used to learn versatilely applicable skills that generalize over a range of tasks specified by a context vector. In this work, we combine contextual policy search with ideas from active learning for selecting the task in which the next trial will be performed. Moreover, we use active training set selection for reducing detrimental effects of exploration in the sampling policy. A core challenge in this approach is that the distribution of the obtained rewards may not be directly comparable between different tasks. We propose the novel approach PUBSVE for estimating a reward baseline and investigate empirically on benchmark problems and simulated robotic tasks to which extent this method can remedy the issue of non-comparable reward.},
	language = {en},
	urldate = {2015-05-05},
	number = {"Advances in Autonomous Learning"},
        publisher={Springer Berlin Heidelberg},
	journal = {German Journal of Artificial Intelligence},
	author = {Fabisch, Alexander and Metzen, Jan Hendrik and Krell, Mario Michael and Kirchner, Frank},
	month = may,
	year = {2015},
	keywords = {Active learning, Artificial Intelligence (incl. Robotics), Contextual policy search, Multi-task learning, Software Engineering/Programming and Operating Systems},
	pages = {1--9},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Reinforcement Learning}
}

@inproceedings{kohler_concept_2015,
	title = {Concept of a {Data} {Thread} {Based} {Parking} {Space} {Occupancy} {Prediction} in a {Berlin} {Pilot} {Region}},
	abstract = {In the presented research project, a software and Hardware infrastructure for parking space focussed inter-modal route planning in a public pilot region in Berlin is developed. One central topic is the development of a prediction system which gives an estimated occupancy for the parking spaces in the pilot region for a given date and time in the future. Occupancy data will be collected online by roadside parking sensors developed within the project. The occupancy prediction will be implemented using \&\#8220;Neural Gas\&\#8221; machine learning in combination with a proposed method which uses data threads to improve the prediction quality. In this paper, a short overview of the whole research Project is given. Furthermore, the concept of the software Framework and the learning methods are presented and first collected data is shown. The prediction method using data threads is explained in more detail.},
	booktitle = {Papers from the 2015 {AAAI} {Workshop}. {Workshop} on {AI} for {Transportation} ({WAIT}-2015), {January} 25-26, {Austin}, {USA}},
	publisher = {AAAI Press},
	author = {K{\"o}hler, Tim and V{\"o}gele, Thomas and Krell, Mario Michael and Metzen, Jan Hendrik and Kirchner, Frank},
	year = {2015}
}

@article{fabisch_active_2014,
	title = {Active Contextual Policy Search},
	abstract = {We consider the problem of learning skills that are versatilely applicable. One popular approach for learning such skills is contextual policy search in which the individual tasks are represented as context vectors. We are interested in settings in which the agent is able to actively select the tasks that it examines during the learning process. We argue that there is a better way than selecting each task equally often because some tasks might be easier to learn at the beginning and the knowledge that the agent can extract from these tasks can be transferred to similar but more dificult tasks. The methods that we propose for addressing the task-selection problem model the learning process as a nonstationary multi-armed bandit problem with custom intrinsic reward heuristics so that the estimated learning progress will be maximized. This approach does neither make any assumptions about the underlying contextual policy search algorithm nor about the policy representation. We present empirical results on an artificial benchmark problem and a ball throwing problem with a simulated Mitsubishi {PA}-10 robot arm.},
	journal = {Journal of Machine Learning Research},
	author = {Fabisch, Alexander and Metzen, Jan Hendrik},
        year = {2014},     
        volume  = {15},
        pages   = {3371-3399},
        url     = {http://jmlr.org/papers/v15/fabisch14a.html},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Reinforcement Learning},
        Local-Url = "../files/fabisch14a.pdf"
}

@inproceedings{senger_velocity-based_2014,
	address = {Stockholm, Sweden},
	title = {Velocity-Based Multiple Change-point Inference for Unsupervised Segmentation of Human Movement Behavior},
	abstract = {In order to transfer complex human behavior to a robot, segmentation methods are needed which are able to detect central movement patterns that can be combined to generate a wide range of behaviors. We propose an algorithm that segments human movements into behavior building blocks in a fully automatic way, called velocity-based multiple change-point inference ({vMCI}). Based on characteristic bell-shaped velocity patterns that can be found in point-to-point arm movements, the algorithm infers segment borders using Bayesian inference. Different segment lengths and variations in the movement execution can be handled. Moreover, the number of segments the movement is composed of need not be known in advance. Several experiments are performed on synthetic and motion capturing data of human movements to compare {vMCI} with other techniques for unsupervised segmentation. The results show that {vMCI} is able to detect segment borders even in noisy data and in demonstrations with smooth transitions between segments.},
	booktitle = {Proceedings of the 22nd International Conference on Pattern Recognition},
	author = {Senger, Lisa and Schr{\"o}er, Martin and Metzen, Jan Hendrik and Kirchner, Elsa A.},
	year = {2014},
        bib2html_pubtype = {Refereed Conference}
}

@phdthesis{metzen_learning_2014,
	address = {Bremen},
	type = {{PhD} Thesis},
	title = {Learning the Structure of Continuous Markov Decision Processes},
	url = {http://nbn-resolving.de/urn:nbn:de:gbv:46-00103656-17},
	abstract = {There is growing interest in artificial, intelligent agents which can operate autonomously for an extended period of time in complex environments and fulfill a variety of different tasks. Such agents will face different problems during their lifetime which may not be foreseeable at the time of their deployment. Thus, the capacity for lifelong learning of new behaviors is an essential prerequisite for this kind of agents as it enables them to deal with unforeseen situations.
However, learning every complex behavior anew from scratch would be cumbersome for the agent. It is more plausible to consider behavior to be modular and let the agent acquire a set of reusable building blocks for behavior, the so-called skills. These skills might, once acquired, facilitate fast learning and adaptation of behavior to new situations. This work focuses on computational approaches for skill acquisition, namely which kind of skills shall be acquired and how to acquire them. The former is commonly denoted as "skill discovery" and the latter as "skill learning".
The main contribution of this thesis is a novel incremental skill acquisition approach which is suited for lifelong learning. In this approach, the agent learns incrementally a graph-based representation of a domain and exploits certain properties of this graph such as its bottlenecks for skill discovery. This thesis proposes a novel approach for learning a graph-based representation of continuous domains based on formalizing the problem as a probabilistic generative model. Furthermore, a new incremental agglomerative clustering approach for identifying bottlenecks of such graphs is presented.
Thereupon, the thesis proposes a novel intrinsic motivation system which enables an agent to intelligently allocate time between skill discovery and skill learning in developmental settings, where the agent is not constrained by external tasks. The results of this thesis show that the resulting skill acquisition approach is suited for continuous domains and can deal with domain stochasticity and different explorative behavior of the agent. The acquired skills are reusable and versatile and can be used in multi-task and lifelong learning settings in high-dimensional problems.},
	language = {English},
	school = {Universit{\"a}t Bremen},
	author = {Metzen, Jan Hendrik},
	year = {2014},
	keywords = {graph, hierarchical-rl, motivation, reinforcement-learning, skill-discovery},
        bib2html_pubtype = {Thesis},
        bib2html_rescat = {Reinforcement Learning},
        Local-Url = "../files/phd_thesis.pdf"
}

@article{krell_pyspace_2013,
	title = {{pySPACE} - A Signal Processing and Classification Environment in Python},
	volume = {7},
	abstract = {In neuroscience large amounts of data are recorded to provide insights into cerebral information processing and function. The successful extraction of the relevant signals becomes more and more challenging due to increasing complexities in acquisition techniques and questions addressed. Here, automated signal processing and machine learning tools can help to process the data, e.g., to separate signal and noise. With the presented software {pySPACE} (http://pyspace.github.io/pyspace), signal processing algorithms can be compared and applied automatically on time series data, either with the aim of finding a suitable preprocessing, or of training supervised algorithms to classify the data. {pySPACE} originally has been built to process multi-sensor windowed time series data, like event-related potentials from the electroencephalogram (EEG). The software provides automated data handling, distributed processing, modular build-up of signal processing chains and tools for visualization and performance evaluation. Included in the software are various algorithms like temporal and spatial filters, feature generation and selection, classification algorithms and evaluation schemes. Further, interfaces to other signal processing tools are provided and, since {pySPACE} is a modular framework, it can be extended with new algorithms according to individual needs. In the presented work, the structural hierarchies are described. It is illustrated how users and developers can interface the software and execute offline and online modes. Configuration of {pySPACE} is realized with the {YAML} format, so that programming skills are not mandatory for usage. The concept of {pySPACE} is to have one comprehensive tool that can be used to perform complete signal processing and classification tasks. It further allows to define own algorithms, or to integrate and use already existing libraries.},
	journal = {Frontiers in Neuroinformatics},
	author = {Krell, Mario M. and Straube, Sirko and Seeland, Anett and W\"{o}hrle, Hendrik and Teiwes, Johannes and Metzen, Jan H. and Kirchner, Elsa A. and Kirchner, Frank},
	year = {2013},
	month = dec,
	pages = {13},
        bib2html_pubtype = {Journal},
        Local-Url = "../files/fninf-pyspace.pdf"
}

@article{metzen_towards_2013,
	title = {Towards Learning of Generic Skills for Robotic Manipulation},
	volume = {28},
	doi = {10.1007/s13218-013-0280-1},
	abstract = {Learning versatile, reusable skills is one of the key prerequisites for autonomous robots. Imitation and reinforcement learning are among the most prominent approaches for learning basic robotic skills. However, the learned skills are often very specific and cannot be reused in different but related tasks. In the project {BesMan}, we develop hierarchical and  transfer learning methods which allow a robot to learn a repertoire of versatile skills that can be reused in different situations. The development of new methods is closely integrated with the analysis of complex human behavior.},
	number = {"Transfer Learning"},
        publisher={Springer Berlin Heidelberg},
	journal = {German Journal of Artificial Intelligence},
	author = {Metzen, Jan Hendrik and Fabisch, Alexander and Senger, Lisa and de Gea Fernandez, Jose and Kirchner, Elsa Andrea},
	year = {2014},
	pages = {15--20},
        note = {the paper is available at \url{http://link.springer.com/article/10.1007%2Fs13218-013-0280-1}},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Reinforcement Learning},
        Local-Url = "../files/ki_besman.pdf"
}


@article{metzen_incremental_2013,
	title = {Incremental Learning of Skill Collections based on Intrinsic Motivation},
	volume = {7},
	number = {11},
	pages = {1--12},
	url = {http://www.frontiersin.org/neurorobotics/10.3389/fnbot.2013.00011/abstract},
	abstract = {Life-long learning of reusable, versatile skills is a key prerequisite for
embodied agents that act in a complex, dynamic environment and are faced with
different tasks over their lifetime.  We address the question of how an agent
can learn useful skills efficiently during a developmental period,
i.e., when no task is imposed on him and no external reward signal is provided.
Learning of skills in a developmental period needs to be incremental and
self-motivated. We propose a new incremental, task-independent skill discovery
approach that is suited for continuous domains. Furthermore, the agent learns
specific skills based on intrinsic motivation mechanisms that
determine on which skills learning is focused at a given point in time. We
evaluate the approach in a reinforcement learning setup in two continuous
domains with complex dynamics. We show that an intrinsically motivated, skill
learning agent outperforms an agent which learns task solutions from scratch.
Furthermore, we compare different intrinsic motivation mechanisms and how
efficiently they make use of the agent's developmental period.},
	urldate = {2013-07-16},
	journal = {Frontiers in Neurorobotics},
	author = {Metzen, Jan Hendrik and Kirchner, Frank},
	year = {2013},
	month = jul,
	keywords = {graph, hierarchical-rl, motivation, skill-discovery, temporal-abstraction},
        Local-Url = "../files/fnbot-07-00011.pdf",
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Reinforcement Learning}
}

@inproceedings{Metzen:EWRL:2013,
	title = {Learning Skill Templates for Parameterized Tasks},
	booktitle = {11th European Workshop on Reinforcement Learning, (EWRL 2013)},
	author = {Jan Hendrik Metzen and Alexander Fabisch},
	pages = {},
        url = {http://ewrl.files.wordpress.com/2013/06/ewrl11_submission_32.pdf},
        note = {accepted},
	month = aug,
	year = {2013},
	location = {Dagstuhl, Germany},
        abstract = {},
        bib2html_pubtype = {Workshop},
        bib2html_rescat = {Reinforcement Learning}
}

@inproceedings{METZEN:ECML:2013,
	title = {Learning Graph-based Representations for Continuous Reinforcement Learning Domains},
	booktitle = {Proceedings of the European Conference on Machine Learning, (ECML 2013)},
	author = {Jan Hendrik Metzen},
        publisher = {Springer Berlin / Heidelberg},
        note = {the paper is available at \url{http://link.springer.com/chapter/10.1007%2F978-3-642-40988-2_6#}},
	month = sep,
	pages = {81-96},
	year = {2013},
        editor={Blockeel, Hendrik and Kersting, Kristian and Nijssen, Siegfried and Zelezny, Filip},
        publisher={Springer Berlin Heidelberg},
        abstract = {Graph-based domain representations have been used in discrete reinforcement learning domains as basis for, e.g., autonomous skill discovery and representation learning. These abilities are also highly relevant for learning in domains which have structured, continuous state spaces as they allow to decompose complex problems into simpler ones and reduce the burden of hand-engineering features. However, since graphs are inherently discrete structures, the extension of these approaches to continuous domains is not straight-forward. We argue that graphs should be seen as discrete, generative models of continuous domains. Based on this intuition, we define the likelihood of a graph for a given set of observed state transitions and derive a heuristic method entitled FIGE that allows to learn graph-based representations of continuous domains with large likelihood. Based on FIGE, we present a new skill discovery approach for continuous domains. Furthermore, we show that the learning of representations can be considerably improved by using FIGE.},
        Local-Url = "../files/ecml_2013_fige.pdf",
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Reinforcement Learning}
}

@article{Feess:PLOS_ONE:2013,
	title = {Comparison of Sensor Selection Mechanisms for an {ERP-Based} Brain-Computer Interface},
	volume = {8},
	issn = {1932-6203},
	url = {http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0067543},
	abstract = {A major barrier for a broad applicability of brain-computer interfaces ({BCIs)} based on electroencephalography ({EEG)} is the large number of {EEG} sensor electrodes typically used. The necessity for this results from the fact that the relevant information for the {BCI} is often spread over the scalp in complex patterns that differ depending on subjects and application scenarios. Recently, a number of methods have been proposed to determine an individual optimal sensor selection. These methods have, however, rarely been compared against each other or against any type of baseline. In this paper, we review several selection approaches and propose one additional selection criterion based on the evaluation of the performance of a {BCI} system using a reduced set of sensors. We evaluate the methods in the context of a passive {BCI} system that is designed to detect a P300 event-related potential and compare the performance of the methods against randomly generated sensor constellations. For a realistic estimation of the reduced system's performance we transfer sensor constellations found on one experimental session to a different session for evaluation. We identified notable (and unanticipated) differences among the methods and could demonstrate that the best method in our setup is able to reduce the required number of sensors considerably. Though our application focuses on {EEG} data, all presented algorithms and evaluation schemes can be transferred to any binary classification task on sensor arrays.},
	number = {7},
	urldate = {2013-07-03},
	journal = {{PLoS} {ONE}},
	author = {Feess, David and Krell, Mario Michael and Metzen, Jan Hendrik},
	month = jul,
	year = {2013},
	pages = {e67543},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Brain Computer Interface},
        Local-Url = "../files/pone_sensor_selection.pdf"
}

@article{Metzen:JMLRWC:2013:OGAHC,
	title = {Online Skill Discovery using Graph-based Clustering},
	author = {Jan Hendrik Metzen},
	volume = {W\&CP 24},
        journal = {Journal of Machine Learning Research},
        editor = {Marc Peter Deisenroth and Csaba Szepesvari and Jan Peters},
	pages = {77-88},
	year = {2012},
        abstract = {We introduce a new online skill discovery method for reinforcement learning in
discrete domains. The method is based on the bottleneck principle and identifies
skills using a bottom-up hierarchical clustering of the estimated transition
graph. In contrast to prior clustering approaches, it can be used
incrementally and thus several times during the learning process. Our empirical
evaluation shows that ``assuming high connectivity in the face of uncertainty''
can prevent premature identification of skills. Furthermore, we show that the
choice of the linkage criterion is crucial for dealing with non-random sampling
policies and stochastic environments.},
        Local-Url = "../files/jmlr_wcp24_ogahc.pdf",
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Reinforcement Learning}
}

@inproceedings{Metzen:EWRL:2012:OGAHC,
	title = {Online Skill Discovery using Graph-based Clustering},
	booktitle = {10th European Workshop on Reinforcement Learning, (EWRL 2012)},
	author = {Jan Hendrik Metzen},
	pages = {},
	month = jun,
	year = {2012},
	location = {Edinburgh, Scotland},
        abstract = {We introduce a new online skill discovery method for reinforcement learning in
discrete domains. The method is based on the bottleneck principle and identifies
skills using a bottom-up hierarchical clustering of the estimated transition
graph. In contrast to prior clustering approaches, it can be used
incrementally and thus several times during the learning process. Our empirical
evaluation shows that ``assuming high connectivity in the face of uncertainty''
can prevent premature identification of skills. Furthermore, we show that the
choice of the linkage criterion is crucial for dealing with non-random sampling
policies and stochastic environments.},
        Local-Url = "../files/ewrl_2012_ogahc.pdf",
        bib2html_pubtype = {Workshop},
        bib2html_rescat = {Reinforcement Learning}
}

@inproceedings{Metzen:EWRL:2012:MBEPS,
	title = {Model-based Evolutionary Policy Search for Skill Learning in Continuous Domains},
	booktitle = {10th European Workshop on Reinforcement Learning, (EWRL 2012)},
	author = {Jan Hendrik Metzen},
	url = {http://www.informatik.uni-bremen.de/~jhm/files/ewrl_2012_mbeps_poster.pdf},
	pages = {},
	month = jun,
	year = {2012},
	location = {Edinburgh, Scotland},
        Local-Url = "../files/ewrl_2012_mbeps_poster.pdf",
        bib2html_pubtype = {Workshop},
        bib2html_rescat = {Reinforcement Learning}
}

@inproceedings{Straube:Neuroscience:2011,
    month = nov,
    year = {2011},
    title = {Choosing an Appropriate Performance Measure: Classification of {EEG}-Data with Varying Class Distribution},
    booktitle = {Proceedings of the 41st Meeting of the Society for Neuroscience 2011},
    location = {Washington DC, United States},
    author = {Sirko Straube and Jan Hendrik Metzen and Anett Seeland and Mario Krell and Elsa Andrea Kirchner},
    bib2html_pubtype = {Workshop},
    bib2html_rescat = {Brain Computer Interface}
}

@inproceedings{Metzen:GFKL:2011,
	title = {Rapid Adaptation of Brain Reading Interfaces based on Threshold Adjustment},
	booktitle = {Proceedings of the 2011 Conference of the German Classification Society, (GfKl-2011)},
	author = {Jan Hendrik Metzen and Elsa Andrea Kirchner},
	pages = {138},
	month = aug,
	year = {2011},
	location = {Frankfurt, Germany},
	Local-Url = "../files/gfkl_2011_abstract",
        bib2html_pubtype = {Workshop},
        bib2html_rescat = {Brain Computer Interface}
}

@inproceedings{Metzen:DAGM:2011,
	author = {Jan Hendrik Metzen and {Su-Kyoung} Kim and Elsa Andrea Kirchner},
	title = {Minimizing Calibration Time for Brain Reading},
        booktitle = {Pattern Recognition},
        series = {Lecture Notes in Computer Science},
        publisher = {Springer Berlin / Heidelberg},
        isbn = {978-3-642-23122-3},
	pages = {366--375},
        volume = {6835},
	month = aug,
	year = {2011},
	location = {Heidelberg, Germany},
        note={The original publication is available under \url{http://link.springer.com/chapter/10.1007%2F978-3-642-23123-0_37}},
        abstract = {Machine learning is increasingly used to autonomously adapt brain-machine
interfaces to user-specific brain patterns. In order to
minimize the
preparation time of the system, it is highly desirable to reduce the length of
the calibration procedure, during which training data is acquired from the user,
to a minimum. One recently proposed approach is to reuse models that have been
trained in historic usage sessions of the same or other users by utilizing an
ensemble-based approach. In this work, we propose two extensions of this
approach which are based on the idea to combine predictions made by
the historic ensemble with session-specific predictions that become available
once a small amount of training data has been collected. These extensions are
particularly useful for Brain Reading Interfaces (BRIs), a specific kind
of brain-machine interfaces. BRIs do not require that user
feedback is given and thus, additional training data may be acquired
concurrently to the usage session. Accordingly, BRIs should initially
perform well when only a small amount of training data acquired in a
short calibration procedure is available and allow an increased performance
when more training data becomes available during the usage session. An
empirical offline-study in a testbed for the use of BRIs to support robotic
telemanipulation shows that the proposed extensions allow to achieve this
kind of behavior.},
	Local-Url = "../files/DAGM_2011.pdf",
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Brain Computer Interface}
}

@inproceedings{Metzen:SSP:2011,
	title = {On Transferring Spatial Filters in a Brain Reading Scenario},
        booktitle={Statistical Signal Processing Workshop (SSP), 2011 IEEE},
	author = {Jan Hendrik Metzen and Su Kyoung Kim and Timo Duchrow and Elsa Andrea Kirchner and Frank Kirchner},
        isbn = {978-1-4577-0569-4},
	pages = {797--800},
        month=jun,
	year = {2011},
        abstract = {Machine learning approaches are increasingly used in brain-machine-interfaces to
allow automatic adaptation to user-specific brain
patterns. One of the most crucial factors for the practical success of these
systems is that this adaptation can be achieved with a minimum amount of
training data since training data needs to be recorded during a
calibration procedure prior to the actual usage session. To this end, one
promising approach is to reuse models based on data recorded in preceding
sessions of the same or of other users. In this paper, we investigate
under which conditions it is favorable to reuse models (more specifically
spatial filters) trained on data from historic sessions compared to learning new
spatial filters on the current session's calibration data. We present an
empirical study in a scenario in which Brain Reading, a particular kind of
brain-machine-interface, is used to support robotic telemanipulation.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Brain Computer Interface}
}

@inproceedings{Kirchner:ISAIRAS:2010,
	title = {Towards Operator Monitoring via Brain Reading - An {EEG-based} Approach for Space Applications},
	booktitle = {Proceedings of the 10th International Symposium on Artificial Intelligence, Robotics and Automation in Space {(iSAIRAS-10)}},
	author = {Elsa Andrea Kirchner and Hendrik W\"{o}hrle and Constantin Bergatt and {Su-Kyoung} Kim and Jan Hendrik Metzen and David Feess and Frank Kirchner},
	month = sep,
	year = {2010},
	pages = {448--455},
	url = {http://www.dfki.de/web/research/ric/publications/renameFileForDownload?filename=110722_Towards%20Operator%20Monitoring%20via%20Brain%20Reading%20-%20An%20EEG-based%20Approach_iSAIRAS_EKirchner.pdf&file_id=uploads_1087},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Brain Computer Interface}
}

@inproceedings{Metzen:AAMAS:2010,
	address = {Richland, {SC}},
	series = {{AAMAS} '10},
	title = {Model-based direct policy search},
	isbn = {978-0-9826571-1-9},
	location = {Toronto, Canada},
	url = {http://portal.acm.org/citation.cfm?id=1838206.1838495},
	booktitle = {Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Jan Hendrik Metzen and Frank Kirchner},
	year = {2010},
	pages = {1589--1590},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Reinforcement Learning}
}

@article{Metzen:KI:2009,
	title = {Learning to Play the {BRIO} Labyrinth Game},
	volume = {Themenheft Reinforcement Learning},
	journal = {Zeitschrift f\"{u}r K\"{u}nstliche Intelligenz},
	author = {Jan Hendrik Metzen and Elsa Andrea Kirchner and Larbi Abdenebaoui and Frank Kirchner},
	year = {2009},
	pages = {34--37},
	url = {http://www.kuenstliche-intelligenz.de/fileadmin/template/main/archiv/pdf/ki2009-03_page34_web_teaser.pdf},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Reinforcement Learning}
}

@article{Metzen:IVC:2009,
	title = {Matching of anatomical tree structures for registration of medical images},
	volume = {27},
	issn = {0262-8856},
	url = {http://dx.doi.org/10.1016/j.imavis.2008.04.002},
	doi = {10.1016/j.imavis.2008.04.002},
	number = {7},
	journal = {Image and Vision Computing},
	author = {Jan Hendrik Metzen and Tim Kr\"{o}ger and Andrea Schenk and Stephan Zidowitz and {Heinz-Otto} Peitgen and Xiaoyi Jiang},
	month = jun,
	year = {2009},
	pages = {923--933},
        abstract = {Many medical applications require a registration of different images of the same organ. In many cases, such a registration is accomplished by manual placement of landmarks in the images. In this paper we propose a method which is able to find reasonable landmarks automatically. To achieve this, bifurcations of the vessel systems, which have been extracted from the images by a segmentation algorithm, are assigned by the so-called association graph method  and the coordinates of these matched bifurcations can be used as landmarks for a non-rigid registration algorithm. Several constraints to be used in combination with the association graph method are proposed and evaluated on a ground truth consisting of anatomical trees from liver and lung.  Furthermore, a method for preprocessing (tree pruning) as well as for postprocessing (clique augmentation) are proposed and evaluated on this ground truth. The proposed method achieves promising results for anatomical trees of liver and lung and for medical images obtained with different modalities and at different points in time.},
        bib2html_pubtype = {Journal},
        bib2html_rescat = {Graph Matching}
}

@inproceedings{Bergatt:LEMIR:2009,
	address = {Bled, Slovenia},
	title = {Quantification and Minimization of the {Simulation-Reality-Gap} on a {BRIO} Labyrinth Game},
	booktitle = {Proceedings of the first International Workshop on Learning and Data Mining for Robotics {(LEMIR-09)}},
	author = {Constantin Bergatt and Jan Hendrik Metzen and Elsa Andrea Kirchner and Frank Kirchner},
	year = {2009},
        bib2html_pubtype = {Workshop},
}

@inproceedings{Kirchner:MLRTA:2009,
	address = {Paderborn},
	title = {Assisting Telemanipulation Operators via {Real-Time} Brain Reading},
	isbn = {1869-2087},
	url = {http://robotik.dfki-bremen.de/fileadmin/CONTENT/Forschung/Projekte/underwater/VI-Bot/Kirchner_Assisting_Telemanipulation_Operators_via_BR_FINAL.pdf},
	booktitle = {Lemgoer Schriftenreihe zur industriellen Informationstechnik},
	author = {Elsa Andrea Kirchner and Jan Hendrik Metzen and Timo Duchrow and Su Kyong Kim and Frank Kirchner},
	month = sep,
	year = {2009},
        bib2html_pubtype = {Workshop},
        bib2html_rescat = {Brain Computer Interface}
}

@incollection{Kassahun:CIARS:2009,
	title = {Incremental Acquisition of Neural Structures through Evolution},
	url = {http://dx.doi.org/10.1007/978-3-540-89933-4_10},
	booktitle = {Design and Control of Intelligent Robotic Systems},
	author = {Yohannes Kassahun and Jan Hendrik Metzen and Mark Edgington and Frank Kirchner},
	year = {2009},
	pages = {187--208},
        bib2html_pubtype = {Book chapter},
        bib2html_rescat = {Neuroevolution}
}

@inproceedings{Metzen:PPSN:2008,
	title = {Evolving Neural Networks for Online Reinforcement Learning},
	url = {http://dx.doi.org/10.1007/978-3-540-87700-4_52},
	booktitle = {Parallel Problem Solving from Nature -- {PPSN} X},
	author = {Jan Hendrik Metzen and Mark Edgington and Yohannes Kassahun and Frank Kirchner},
	month = sep,
	year = {2008},
	pages = {518--527},
        abstract = {For many complex Reinforcement Learning problems with large and continuous state spaces, neuroevolution (the evolution of artificial neural networks) has achieved promising results. This is especially true when there is noise in sensor and/or actuator signals. These results have mainly been obtained in offline learning settings, where the training and evaluation phase of the system are separated. In contrast, in online Reinforcement Learning tasks where the actual performance of the systems during its learning phase matters, the results of neuroevolution are significantly impaired by its purely exploratory nature, meaning that it does not use (i.e. exploit) its knowledge of the performance of single individuals in order to improve its performance during learning. In this paper we describe modifications which significantly improve the online performance of the neuroevolutionary method Evolutionary Acquisition of Neural Topologies (EANT) and discuss the results obtained on two benchmark problems.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution, Reinforcement Learning}
}

@inproceedings{Roemmermann:PPSN:2008,
	title = {Learning Walking Patterns for Kinematically Complex Robots Using Evolution Strategies},
	url = {http://dx.doi.org/10.1007/978-3-540-87700-4_108},
	booktitle = {Parallel Problem Solving from Nature -- {PPSN} X},
	author = {Malte R\"{o}mmermann and Mark Edgington and Jan Hendrik Metzen and Jose de Gea and Yohannes Kassahun and Frank Kirchner},
	year = {2008},
	pages = {1091--1100},
        bib2html_pubtype = {Refereed Conference},
}

@inproceedings{Kassahun:GECCO:2008,
	address = {New York, {NY,} {USA}},
	title = {Accelerating neuroevolutionary methods using a Kalman filter},
	isbn = {978-1-60558-130-9},
	location = {Atlanta, {GA,} {USA}},
	url = {http://dx.doi.org/10.1145/1389095.1389365},
	booktitle = {{GECCO} '08: Proceedings of the 10th annual conference on Genetic and evolutionary computation},
	publisher = {{ACM}},
	author = {Yohannes Kassahun and Jose de Gea and Mark Edgington and Jan Hendrik Metzen and Frank Kirchner},
	year = {2008},
	pages = {1397--1404},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution}
}

@inproceedings{Metzen:GECCO:2008,
	address = {New York, {NY,} {USA}},
	title = {Towards efficient online reinforcement learning using neuroevolution},
	isbn = {978-1-60558-130-9},
	location = {Atlanta, {GA,} {USA}},
	url = {http://dx.doi.org/10.1145/1389095.1389371},
	series = {{GECCO} '08},
	booktitle = {Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation},
	publisher = {{ACM}},
	author = {Jan Hendrik Metzen and Frank Kirchner and Mark Edgington and Yohannes Kassahun},
	year = {2008},
	pages = {1425--1426},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution, Reinforcement Learning}
}

@inproceedings{Metzen:AAMAS:2008,
	address = {Richland, {SC}},
	title = {Analysis of an evolutionary reinforcement learning method in a multiagent domain},
	isbn = {978-0-9817381-0-9},
	location = {Estoril, Portugal},
	url = {http://portal.acm.org/citation.cfm?id=1402428},
	series = {{AAMAS} '08},
	booktitle = {Proceedings of the 7th International Conference on Autonomous Agents and Multiagent Systems},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
	author = {Jan Hendrik Metzen and Mark Edgington and Yohannes Kassahun and Frank Kirchner},
	month = may,
	year = {2008},
	pages = {291--298},
        abstract = {Many multiagent problems comprise subtasks which can be considered as reinforcement learning (RL) problems. In addition to classical temporal difference methods, evolutionary algorithms are among the most  promising approaches for such RL problems. The relative performance of these approaches in certain subdomains (e.\,g. multiagent learning) of the general RL problem remains an open question at this time. In addition to theoretical analysis, benchmarks are one of the most important tools for comparing different RL methods in certain problem domains. A recently proposed multiagent RL benchmark problem is the RoboCup Keepaway benchmark. This benchmark is one of the most challenging multiagent learning problems because its state-space is continuous and high dimensional, and both the sensors and the actuators are noisy.  In this paper we analyze the performance of the neuroevolutionary approach called Evolutionary Acquisition of Neural Topologies (EANT) in the Keepaway benchmark, and compare the results obtained using EANT with the results of other algorithms tested on the same benchmark.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution, Reinforcement Learning}
}


@inproceedings{Metzen:ICMLA:2007,
	address = {Washington, {DC,} {USA}},
	title = {Performance Evaluation of {EANT} in the {RoboCup} Keepaway Benchmark},
	isbn = {0-7695-3069-9},
	url = {http://dx.doi.org/10.1109/ICMLA.2007.80},
	booktitle = {{ICMLA} '07: Proceedings of the Sixth International Conference on Machine Learning and Applications},
	publisher = {{IEEE} Computer Society},
	author = {Jan Hendrik Metzen and Mark Edgington and Yohannes Kassahun and Frank Kirchner},
	year = {2007},
	pages = {342--347},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution, Reinforcement Learning}
}


@inproceedings{Kassahun:GECCO:2007,
	address = {New York, {NY,} {USA}},
	title = {A common genetic encoding for both direct and indirect encodings of networks},
	isbn = {978-1-59593-697-4},
	location = {London, England},
	url = {http://dx.doi.org/10.1145/1276958.1277162},
	booktitle = {{GECCO} '07: Proceedings of the 9th annual conference on Genetic and evolutionary computation},
	publisher = {{ACM}},
	author = {Yohannes Kassahun and Mark Edgington and Jan H Metzen and Gerald Sommer and Frank Kirchner},
	month = jul,
	year = {2007},
	pages = {1029--1036},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution}
}

@inproceedings{Kassahun:KI:2007,
	title = {A General Framework for Encoding and Evolving Neural Networks},
	url = {http://dx.doi.org/10.1007/978-3-540-74565-5_17},
	booktitle = {{KI} 2007: Advances in Artificial Intelligence},
	author = {Yohannes Kassahun and Jan Metzen and Jose de Gea and Mark Edgington and Frank Kirchner},
	year = {2007},
	pages = {205--219},
        address = {Osnabr{\"u}ck, Germany},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Neuroevolution}
}

@inproceedings{Metzen:GBR:2007,
	address = {Alicante, Spain},
	title = {Matching of Tree Structures for Registration of Medical Images},
	url = {http://dx.doi.org/10.1007/978-3-540-72903-7_2},
	booktitle = {{Graph-Based} Representations in Pattern Recognition},
	publisher = {Springer Verlag},
	author = {Jan Metzen and Tim Kr\"{o}ger and Andrea Schenk and Stephan Zidowitz and {Heinz-Otto} Peitgen and Xiaoyi Jiang},
	year = {2007},
	pages = {13--24},
        abstract =  {Many medical applications require a registration of different images of the same organ. In many cases, such a registration is accomplished by manually placing landmarks in the images. In this paper we propose a method which is able to find reasonable landmarks automatically. To achieve this, nodes of the vessel systems, which have been extracted from the images by a segmentation algorithm, will be assigned by the so-called association graph method  and the coordinates of these matched nodes can be used as landmarks for a non-rigid registration algorithm.},
        bib2html_pubtype = {Refereed Conference},
        bib2html_rescat = {Graph Matching}
}

@inproceedings{Metzen:BVM:2007,
	title = {Matching von Baumstrukturen - Zuordnung von Gef\"{a}{\ss}systemen aus Leber und Lunge},
	url = {http://dx.doi.org/10.1007/978-3-540-71091-2_24},
	booktitle = {Bildverarbeitung f\"{u}r die Medizin 2007},
	author = {Jan Hendrik Metzen and Tim Kr\"{o}ger and Andrea Schenk and Stephan Zidowitz and {Heinz-Otto} Peitgen and Xiaoyi Jiang},
        month = {March},
	year = {2007},
	pages = {116--120},
        bib2html_pubtype = {Workshop},
        bib2html_rescat = {Graph Matching}
}

@MastersThesis{Metzen:DA:2006,
  author     = {Jan Hendrik Metzen},
  month      = {July},
  year       = {2006},
  title      = {Matching von {B}aumstrukturen in der medizinischen {B}ildverarbeitung},
  school     = {Westf{\"a}lische Wilhelms-Universit{\"a}t M{\"u}nster},
  month      = {July},
	Local-Url = "../files/Matching_von_Baumstrukturen.pdf",
        bib2html_pubtype = {Thesis},
        bib2html_rescat = {Graph Matching}
}

@InProceedings{Mueller:ACE:2005,
  author    = {Jens M{\"u}ller and Jan Hendrik Metzen and Alexander Ploss and Maraike Schellmann and Sergei Gorlatch},
  title     = {Rokkatan: Scaling an {RTS} Game Design to the Massively Multiplayer Realm},
  booktitle = "ACM SIGHCHI International Conference on Advances in Computer Entertainment Technology (ACE 05)",
  pages     = {125--132},
  year      = {2005},
  month     = {June},
  address   = {Valencia, Spain},
  publisher = {ACM},
  url = {http://pvs.uni-muenster.de/pvs/mitarbeiter/jmueller/rokkatan.pdf},
        bib2html_pubtype = {Refereed Conference},
}

